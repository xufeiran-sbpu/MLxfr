{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load score.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from iforest import IsolationTreeEnsemble, find_TPR_threshold\n",
    "\n",
    "def score(X, y, n_trees, desired_TPR, datafile,sample_size,\n",
    "          reqd_fit_time,\n",
    "          reqd_score_time,\n",
    "          reqd_FPR,\n",
    "          reqd_n_nodes):\n",
    "    it = IsolationTreeEnsemble(sample_size=sample_size, n_trees=n_trees)\n",
    "\n",
    "    fit_start = time.time()\n",
    "    it.fit(X, improved=improved)\n",
    "    fit_stop = time.time()\n",
    "    fit_time = fit_stop - fit_start\n",
    "    print(f\"INFO {datafile} fit time {fit_time:3.2f}s\")\n",
    "\n",
    "    n_nodes = sum([t.n_nodes for t in it.trees])\n",
    "    print(f\"INFO {datafile} {n_nodes} total nodes in {n_trees} trees\")\n",
    "\n",
    "    score_start = time.time()\n",
    "    scores = it.anomaly_score(X)\n",
    "    score_stop = time.time()\n",
    "    score_time = score_stop - score_start\n",
    "    print(f\"INFO {datafile} score time {score_time:3.2f}s\")\n",
    "\n",
    "    threshold, FPR = find_TPR_threshold(y, scores, desired_TPR)\n",
    "\n",
    "    y_pred = it.predict_from_anomaly_scores(scores, threshold=threshold)\n",
    "    confusion = confusion_matrix(y, y_pred)\n",
    "    TN, FP, FN, TP = confusion.flat\n",
    "    TPR = TP / (TP + FN)\n",
    "    FPR = FP / (FP + TN)\n",
    "\n",
    "    errors = 0\n",
    "    if fit_time > reqd_fit_time * 2:\n",
    "        print(f\"FAIL {datafile} fit time {fit_time:.1f} > {reqd_fit_time}\")\n",
    "        errors += 1\n",
    "\n",
    "    if score_time > reqd_score_time * 2:\n",
    "        print(f\"FAIL {datafile} score time {score_time:.1f} > {reqd_score_time}\")\n",
    "        errors += 1\n",
    "\n",
    "    if TPR < desired_TPR*.9: # TPR must be within 10% (or above)\n",
    "        print(f\"FAIL {datafile} TPR {TPR:.2f} < {desired_TPR} +- 10%\")\n",
    "        errors += 1\n",
    "\n",
    "    if FPR > reqd_FPR*1.3: # TPR must be within 30%\n",
    "        print(f\"FAIL {datafile} FPR {FPR:.4f} > {reqd_FPR} +- 30%\")\n",
    "        errors += 1\n",
    "\n",
    "    if n_nodes > reqd_n_nodes*1.15:\n",
    "        print(f\"FAIL {datafile} n_nodes {n_nodes} > {reqd_n_nodes} +- 15%\")\n",
    "        errors += 1\n",
    "\n",
    "    if errors==0:\n",
    "        print(f\"SUCCESS {datafile} {n_trees} trees at desired TPR {desired_TPR*100.0:.1f}% getting FPR {FPR:.4f}%\")\n",
    "    else:\n",
    "        print(f\"ERRORS {datafile} {errors} errors {n_trees} trees at desired TPR  {desired_TPR*100.0:.1f}% getting FPR {FPR:.4f}%\")\n",
    "\n",
    "\n",
    "def score_cc():\n",
    "    df = pd.read_csv(\"creditcard.csv\")\n",
    "    N = 15_000\n",
    "    df = df.sample(N)  # grab random subset (too slow otherwise)\n",
    "    if noise: add_noise(df)\n",
    "    X, y = df.drop('Class', axis=1), df['Class']\n",
    "\n",
    "    score(X, y, n_trees=300, desired_TPR=.8,\n",
    "          datafile='creditcard.csv',sample_size=256,\n",
    "          reqd_fit_time=.45 if noise and improved else 0.4,\n",
    "          reqd_score_time=20,\n",
    "          reqd_FPR=.15 if noise and improved else .08,\n",
    "          reqd_n_nodes=24000 if noise and improved else 27176)\n",
    "\n",
    "\n",
    "def score_http():\n",
    "    df = pd.read_csv(\"http.csv\")\n",
    "    N = 16_000\n",
    "    df = df.sample(N)  # grab random subset (too slow otherwise)\n",
    "    if noise: add_noise(df)\n",
    "    X, y = df.drop('attack', axis=1), df['attack']\n",
    "\n",
    "    score(X, y, n_trees=300, desired_TPR=.99,\n",
    "          datafile='http.csv',sample_size=256,\n",
    "          reqd_fit_time=.37 if noise and improved else 0.2,\n",
    "          reqd_score_time=21 if noise and improved else 13,\n",
    "          reqd_FPR=.22 if noise and improved else 0.006,\n",
    "          reqd_n_nodes=26300 if noise and improved else 22700)\n",
    "\n",
    "\n",
    "def score_cancer():\n",
    "    df = pd.read_csv(\"cancer.csv\")\n",
    "    N = len(df)\n",
    "    df = df.sample(N)  # grab random subset (too slow otherwise)\n",
    "    if noise: add_noise(df)\n",
    "    X, y = df.drop('diagnosis', axis=1), df['diagnosis']\n",
    "\n",
    "    score(X, y, n_trees=1000, desired_TPR=.75,sample_size=5,\n",
    "          datafile='cancer.csv',\n",
    "          reqd_fit_time=0.2,\n",
    "          reqd_score_time=.75,\n",
    "          reqd_FPR=.33,\n",
    "          reqd_n_nodes=8500)\n",
    "\n",
    "\n",
    "def add_noise(df):\n",
    "    n_noise = 5\n",
    "    for i in range(n_noise):\n",
    "        df[f'noise_{i}'] = np.random.normal(0,100,len(df))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    noise = False\n",
    "    improved = False\n",
    "    if '-noise' in sys.argv:\n",
    "        noise = True\n",
    "    if '-improved' in sys.argv:\n",
    "        improved = True\n",
    "\n",
    "    print(f\"Running noise={noise} improved={improved}\")\n",
    "    score_cc()\n",
    "    print()\n",
    "    score_http()\n",
    "    print()\n",
    "    score_cancer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
